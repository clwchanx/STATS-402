---
title: "Cleaning Data"
author: "Clayton Chan"
date: "2024-10-24"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Data Cleaning & EDA

Before we begin our analysis, we must first clean the data. We'll start by looking for some NA values and we have found none. However, this dataset does have a lot of duplicate observations which may indicate that the same exact position was reported multiple times so we will drop the duplicates to remedy that.


```{r}
df <- read.csv("DataScience_salaries_2024.csv")
head(df)
```
```{r}
sum(complete.cases(df)) == nrow(df) #Check for NA Values TRUE means there is none
df <- unique(df) #Get rid of duplicate observations 
```



```{r}
library(tidyverse)
table(df$employment_type)
df <- filter(df,employment_type == 'FT') # We will focus on full time salaries
```

Let's begin the EDA with checking the frequency tables of all our predictors which are categorical.
For the purposes of our analysis, we are only interested in the salaries of full time positions so we will drop any observations that are part-time, freelance, and contract. In fact, this may be a good idea due to how little observations (<<1%) there were in each of these classes


```{r}
table(df$work_year) #Too few observations in 2020-2022 so we'll combine them into "Pandemic Era"
df$work_year <- ifelse(df$work_year == 2024, "2024",
                ifelse(df$work_year == 2023, "2023", "Pandemic"))
df$work_year <- factor(df$work_year,levels = c("Pandemic","2023","2024"))
#Relevel
```
Next we'll look at the work year. We can see that the majority of the data comes from 2023-2024 but there are very few observations in 2020-2022 so we'll combine all the observations from 2020 to 2022 into one category and name it "Pandemic" denoting that the salary came from the pandemic era.


```{r}
table(df$experience_level)
df$experience_level <- factor(df$experience_level, levels = c("EN","MI","SE","EX")) #Relevel
```
Next we'll look at the experience level and this table shows that the levels aren't very balanced, it doesn't look to problematic where we may need to address things with releveling. It's not surprising to see so few executives but the overwhelming majority of the data come from people at the senior and mid level while there aren't many at the entry level.


```{r}
sum(df$employee_residence==df$company_location)/nrow(df)
df <- select(df,-c("employment_type","salary","salary_currency","employee_residence"))
#Get rid of employment type as every observation is full time
#Get rid of salary and currency as we have the salary in USD
#Get rid of employee residence as we already have the company location and the company location 
#matters more for predicting the salary

```

Since all our observations are now full-time we'll drop the employment type column as it won't provide us with any information. Furthermore, since the salary is already given to us in USD, we will drop the salary and salary_currency column as it is redundant. Furthermore, the employee residence is fairly redundant as we have the company location and >98% of the observations have these columns as the same. Even if they aren't, the company's location is more important for determining the salary rather than the employee's place of residence.


```{r}
table(df$remote_ratio)
table(df$company_size)
df$company_size <- factor(df$company_size,levels = c("S","M","L"))
```
Looking at the remote ratio, most of the observations are either in-person or remote with very few hybrid positions but we'll leave it as is since there's still a decent amount of observations with hybrid jobs. Instead of numbers, we'll make things more clear renaming 0 as in-person, 50 as hybrid, and 100 as remote

For the company size, we also see a major imbalance with most coming from a medium sized company but still have a couple hundred coming from a large/small company.


```{r}
df$remote_ratio <- ifelse(df$remote_ratio == 0, "In-Person",
                   ifelse(df$remote_ratio == 100,"Remote","Hybrid"))
df$remote_ratio <- factor(df$remote_ratio, levels = c("In-Person","Hybrid","Remote"))
```

```{r}
library(countrycode)
df$company_location <- countrycode(df$company_location, origin = "iso2c", destination = "country.name")
table(df$company_location)

#list modified to only include world bank high income economies according to
#https://en.wikipedia.org/wiki/Developed_country#cite_note-18
#ref: https://datahelpdesk.worldbank.org/knowledgebase/articles/906519-world-bank-country-and-lending-groups
developed_countries <- c(
  "American Samoa","Andorra","Australia","Austria","Belgium","Canada","Chile","Croatia","Czechia","Denmark",
  "Estonia","Finland","France","Germany","Gibraltar","Greece","Hong Kong SAR China",
  "Ireland","Israel","Italy","Japan","Latvia","Lithuania","Luxembourg","Malta","Netherlands",
  "New Zealand","Norway","Poland","Portugal","Qatar","Romania","Russia","Saudi Arabia","Singapore","Slovenia",
  "South Korea","Spain","Sweden","Switzerland","United Arab Emirates","United Kingdom")

df$company_location <- ifelse(df$company_location == "United States", "US",
                       ifelse(df$company_location %in% developed_countries,"First World","Developing"))
#Combine all first world countries into developed label leaving the rest as the developing countries
df$company_location <- factor(df$company_location, levels = c("US","First World","Developing"))
```
From this table, we can see that our data came from all over the globe. While the diversity is great, there are way too many levels that also have too little observations which suggests we should relevel everything. We will combine all the countries with booming economies as First World Countries, all the third world countries as developing, and leaving the USA as its own category to have a baseline.

```{r}
table(df$company_location)
```


```{r}
table(df$job_title)
titles <- names(table(df$job_title))
analyst <- c(titles[c(1,40,44:51,67,75,78,93,103:104,109,126,134,139,148)])
scientist <- c(titles[c(13,79:89,99,106,111,125,128,137,149)])
mle <- c(titles[c(14:15,107,112:123,129:131,138)])
engineer <- c(titles[c(20,27,38:39,54:56,58,69,72,76,94,110,127,136,147,150)])
BI <- c(titles[c(21:24,28:36,133)])
df$job_title <- ifelse(df$job_title %in% analyst, "DA",
                ifelse(df$job_title %in% scientist,"DS",
                ifelse(df$job_title %in% engineer, "DE",
                ifelse(df$job_title %in% mle,"ML",
                ifelse(df$job_title %in% BI,"BI","Other")))))
df$job_title <- relevel(factor(df$job_title), ref = "DA")
#Condense all titles with data science in the name to data scientist and repeat for analysts, MLE and etc
```
For the job titles column we can see the same issue where we have a lot of different levels with too few observations. Furthermore some of these titles are really similar and it would make more sense to combine them. For example, Staff Data Scientist and Data Scientist should not be different categories. So what we ended up doing is combining all the Data Engineer titles as DE, all the Data Analyst titles as DA, all the Data Scientist titles as DS, all the Machine Learning titles as ML, all the Business Intelligence roles as BI and the rest as Other and we end up with something that has a good amount of observations per level.


```{r}
table(df$job_title)
```

```{r}
hist(df$salary_in_usd,xlab="Salary in USD",main = "Histogram of Salary in USD")
```
Looking at this salary, we can see that the salaries are clearly skewed right and not many people earn income in the upper bracket. This might also suggest that we should consider a transformation as this is our response variable.

# Codebook

With our cleaned data, let's summarize all the information in our data. \newline

work_year:Describes what year the salary came from. Ordinal variable with 3 levels. "Pandemic", "2023", "2024" \newline
experience_level: Describes level of experience for the role. Ordinal variable with 4 levels. "EN"=Entry Level "MI"=Mid-Level "SE"=Senior "EX"=Executive \newline
job_title: Describes the job title and what kind of work is done. Nominal variable with 6 levels. "DA"=Data Analyst "BI"=Business Intelligence "DE"=Data Engineer "DS"=Data Science "ML"=Machine Learning "Other" \newline
salary_in_usd:The salary in USD which is a quantitative variable \newline
remote_ratio: Describes the format of the job. Nominal variable with 3 levels. "In-Person","Hybrid","Remote"\newline
company_location:Describes what kind of country this job came from. Nominal variable with 3 levels. "US" "First World" "Developing"\newline
company_size: Describes the size of the company. Ordinal variable with 3 levels. "S"=Small "M"=Medium "L" = Large

salary_in_usd is not very symmetrical. Use symbox() to find best transformation
```{r}
library(car)
symbox(df$salary_in_usd)
hist(log(df$salary_in_usd),xlab="Salary in USD",main = "Histogram of Salary in USD")
df$salary_in_usd = log(df$salary_in_usd)
```
Now we can run ANOVA on all independent variables and all interaction effects.
This will give us an idea of what to use in the regression model.
```{r}
m_aov <- aov(salary_in_usd~.^2,data=df)
summary(m_aov)
```
Seems like all individual variables are statistically significant.
Interaction effects, while many are significant, I will select only 1 highly significant that has intuition.
```{r}
m = lm(
  salary_in_usd~work_year+experience_level+job_title+remote_ratio+company_location+company_size+experience_level*company_location,
  data=df)

summary(m)
```
I also want to run a regression with only inidividiaul variables to see the R^2 change by including interaction effect
```{r}
m_ind = lm(
  salary_in_usd~work_year+experience_level+job_title+remote_ratio+company_location+company_size,
  data=df)

summary(m_ind)
```
#Cross-Validation
```{r}
library(caret)

# Setting up cross-validation, 10-fold
control <- trainControl(method = "cv", number = 10) 

# First we cross validate the model that contains individual variables and interaction effect
model_interaction_cv <- train(salary_in_usd ~ work_year + experience_level + job_title +
                              remote_ratio + company_location + company_size +
                              experience_level * company_location,
                              data = df,
                              method = "lm",
                              trControl = control)

print(model_interaction_cv)

# Then we proceed with the model that contains individual variables only
model_main_cv <- train(salary_in_usd ~ work_year + experience_level + job_title +
                       remote_ratio + company_location + company_size,
                       data = df,
                       method = "lm",
                       trControl = control)

print(model_main_cv)
```

```{r}
library(caret)

# Setting up cross-validation, LOOCV
control_loocv <- trainControl(method = "LOOCV")

# Model with only main effects
model_main_loocv <- train(salary_in_usd ~ work_year + experience_level + job_title +
                          remote_ratio + company_location + company_size,
                          data = df,
                          method = "lm",
                          trControl = control_loocv)

print(model_main_loocv)

# Model with main effects and interaction terms
model_interaction_loocv <- train(salary_in_usd ~ work_year + experience_level + job_title +
                                 remote_ratio + company_location + company_size +
                                 experience_level * company_location,
                                 data = df,
                                 method = "lm",
                                 trControl = control_loocv)

print(model_interaction_loocv)
```
With a slightly lower RMSE and MAE values, also a higher Rsquared value in both k-fold Cross Validation and LOOCV, We consider the model with interaction effect as the better model for our predictions

```{r}
#comparing AIC of these two models
AIC(m)
AIC(m_ind)
```
